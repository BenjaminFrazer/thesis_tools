* Code Documentation
This README contains documentation on the code used in my MSc Thesis project. All code packaged as a pip package split into two main sub modules relating to specific functionality
  + Dataset synthesis
  + General utility (plots paths)

* Table of Contents :TOC_1:
- [[#code-documentation][Code Documentation]]
- [[#install-guide][Install Guide]]
- [[#dependencies][Dependencies]]
- [[#quick-start-guide][Quick-start Guide]]
- [[#dataset-generation][Dataset Generation]]

* Install Guide
These steps will install A) my fork of NILMTK B) nilm_metadata C) the thesis_tools repo itself. Note that the thesis_tools repo *must* be installed from a cloned repo because it expects data files which exist relative to the package directory.
#+begin_src shell
pip install git+https://github.com/nilmtk/nilm_metadata/@0.2.4
pip install git+https://github.com/BenjaminFrazer/nilmtk/@benDevel
git clone -e https://github.com/BenjaminFrazer/thesis_tools <yourDesiredPath>
cd <yourDesiredPath>
pip install -e .
#+end_src

Optionally the contrib package containing advanced NILM algorithms may be installed using the following command when using bash:
#+begin_src shell
pip install -e git+https://github.com/nilmtk/nilmtk-contrib#egg=nilmtk-contrib
#+end_src

Or with zsh (hash is a special character that must be escaped with zsh):
#+begin_src shell
pip install -e git+https://github.com/nilmtk/nilmtk-contrib'#'egg=nilmtk-contrib
#+end_src

âš  I faced difficulty getting NILMTK-contrib working with pip due to broken package dependencies. This can be worked around to get some of the algorithms working by editing the package source as detailed in [[file:../guides/nilmtk_install_guide.org][this guide]].

* Dependencies
| Name                   |       Version |
|------------------------+---------------|
| Python                 |           3.8 |
| Pandas                 |        0.25.3 |
| Numpy                  | 1.19.3-1.19.5 |
| [[https://github.com/BenjaminFrazer/nilmtk.git][BenjaminFrazer/NILMTK]]* |         0.4.3 |
| [[https://github.com/nilmtk/nilmtk-contrib][NILMTK-contrib]]**       |         0.1.2 |
| [[https://github.com/nilmtk/nilm_metadata/][NILM-Metadata]]          |         0.2.4 |

*Notes:*

*The author's fork of the NILMTK is used in this work which includes several improvements in the way in which the experimentation API records result. These changes were necessitated by the large number of data-points generated by the parameter sweeps used in this work. These changes are non breaking and have been build with reintegration into NILMTK in mind. Full documentation of these changes can be found in the repository itself.

**Optional: Only required for advanced NILM algorithms.

* TODO Quick-start Guide
** TODO Running NILM Experiments & Test sweeps
Replicating the experimental results generated in this work should be trivial using the [[file:../scripts/run_testsweep.py][run_testsweep.py]] script provided and configuring which power/temporal aggregation test cases you wish to sweep as follows:

Replicating sweep of power aggregation level at Ts: =2min=:
#+begin_src python
##### Experiment Configureation ####################################
power_agg_levels_2_test = [1,2,3,4,5]
samplePeriods2Test_s= [120]
# samplePeriods2Test= [300*60] #[(x+1)*60 for x in range(15)]
dateString = (datetime.datetime.now()).strftime("%d-%m-%y")
sweep_summary_file = paths.results+f"/PowAggSweep_summary_{dateString}.csv"
results_fstring= "/PowAggSweep_{dateString}_PAgg{pAgg}_Ts{Ts}.hdf5"
#+end_src

Replicating a sweep of temporal aggregation (sample period) at power aggregations =1,3,5=:
#+begin_src python
##### Experiment Configureation ####################################
power_agg_levels_2_test = [1,3,5]
samplePeriods2Test = [(x+1)*60 for x in range(15)]
dateString = (datetime.datetime.now()).strftime("%d-%m-%y")
sweep_summary_file = paths.results+f"/TempAggSweep_summary_{dateString}.csv"
results_fstring= "/TempAggSweep_{dateString}_PAgg{pAgg}_Ts{Ts}.hdf5"
#+end_src

*** Configuring disaggregation algorithms to test
This can be configured by simply commenting out or adding disaggregation algorithms in =construct_experiment_dic()=, for example if we wish not to use =DAE=:
#+begin_src python
experiment = {
    ...
    # here we specify which disaggregation algorithms we wish to test
    'methods': {"CO":CO({}),
                "FMHH":FHMMExact({'num_of_states':2}),
                'Mean':Mean({}),
                 # "DAE":DAE({}),
                 'Seq2Point':Seq2Point({}),
                 'Seq2Seq':Seq2Seq({})
                },
    ...
#+end_src


*** Further configuration
The =run_testsweep.py= script is simply wrapped around the modified NILMTK experimentation API. As such any details on any further configuration options can be found in the main [[https://github.com/nilmtk/nilmtk/tree/master/docs/manual][NILMTK wiki]].

** TODO Plotting Results
* TODO Dataset Generation
This repository uses all of the code used to generate the synthetic NILM datasets presented in this work. Since only part of the source dataset is publicly available, it is not possible to directly generate the same or new datasets with this code, however inspection of this code may be of value to understand the [[file:../data/readme.org][datasets]] that are presented in this work.
[[file:../figures/DataSynthesisPipeline.png]]
